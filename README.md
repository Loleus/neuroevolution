**Neuroewolucja** to technika uczenia maszynowego, ktÃ³ra Å‚Ä…czy dwie fundamentalne idee:
- **Sieci neuronowe** â€“ matematyczne modele inspirowane budowÄ… mÃ³zgu, zdolne do uczenia siÄ™ zadaÅ„ poprzez dostosowywanie wag pomiÄ™dzy neuronami.
- **Algorytmy genetyczne** â€“ metody optymalizacji inspirowane ewolucjÄ… biologicznÄ…, gdzie populacja rozwiÄ…zaÅ„ ewoluuje poprzez selekcjÄ™, krzyÅ¼owanie i mutacjÄ™.

W neuroewolucji **wagi sieci neuronowej** traktowane sÄ… jako **genotyp** (zestaw cech dziedziczonych), a **jakoÅ›Ä‡ rozwiÄ…zania** (np. zdolnoÅ›Ä‡ do przejÅ›cia labiryntu) jako **fitness** (przystosowanie). Populacja sieci neuronowych ewoluuje, by coraz lepiej rozwiÄ…zywaÄ‡ postawione zadanie.

### Zalety w porÃ³wnaniu do samodzielnej sieci neuronowej
| Aspekt | SieÄ‡ neuronowa (uczenie gradientowe) | Neuroewolucja |
|--------|--------------------------------------|---------------|
| **Wymagania wstÄ™pne** | Potrzebuje zestawu danych treningowych (wejÅ›cieâ€“wyjÅ›cie) | **Nie potrzebuje danych** â€“ uczy siÄ™ przez interakcjÄ™ ze Å›rodowiskiem |
| **Problem gradientu** | Wymaga rÃ³Å¼niczkowalnej funkcji celu; Å‚atwo utknÄ…Ä‡ w minimum lokalnym | **Nie uÅ¼ywa gradientu** â€“ przeszukuje przestrzeÅ„ rozwiÄ…zaÅ„ globalnie |
| **OdpornoÅ›Ä‡ na szum** | CzÄ™sto wraÅ¼liwa na zakÅ‚Ã³cenia w danych | **Bardziej odporna** â€“ rÃ³Å¼norodnoÅ›Ä‡ populacji pomaga znaleÅºÄ‡ stabilne rozwiÄ…zania |
| **Eksploracja** | Zwykle eksploruje wokÃ³Å‚ poczÄ…tkowego punktu | **Eksploruje szeroko** dziÄ™ki mutacjom i krzyÅ¼owaniu |

### Zalety w porÃ³wnaniu do samodzielnego algorytmu genetycznego
| Aspekt | Algorytm genetyczny (bez sieci) | Neuroewolucja |
|--------|----------------------------------|---------------|
| **Reprezentacja rozwiÄ…zania** | Zwykle wektor liczb (geny) | **SieÄ‡ neuronowa** â€“ zdolna do przetwarzania zÅ‚oÅ¼onych danych sensorycznych |
| **Generalizacja** | RozwiÄ…zanie dopasowane do konkretnego przypadku | SieÄ‡ moÅ¼e **uogÃ³lniaÄ‡** na podobne sytuacje (np. inne ukÅ‚ady Å›cian) |
| **CiÄ…gÅ‚oÅ›Ä‡ przestrzeni** | Dyskretne lub ciÄ…gÅ‚e geny | Wagowa przestrzeÅ„ ciÄ…gÅ‚a â€“ **pÅ‚ynne dostosowanie** zachowania |
| **ZdolnoÅ›Ä‡ adaptacyjna** | StaÅ‚y zestaw reguÅ‚ | SieÄ‡ moÅ¼e **dynamicznie reagowaÄ‡** na zmieniajÄ…ce siÄ™ warunki |

Neuroewolucja Å‚Ä…czy **elastycznoÅ›Ä‡ sieci neuronowych** w przetwarzaniu danych z **globalnymi moÅ¼liwoÅ›ciami przeszukiwania algorytmÃ³w genetycznych**. Jest szczegÃ³lnie przydatna, gdy:
- Nie mamy danych treningowych (uczenie przez wzmocnienie),
- PrzestrzeÅ„ rozwiÄ…zaÅ„ jest wielowymiarowa i peÅ‚na minimÃ³w lokalnych,
- Potrzebujemy rozwiÄ…zania odpornego na zmiany Å›rodowiska.

---

## Architektura symulacji

### 1. Åšrodowisko â€“ labirynt
- Wymiary: 320Ã—320 pikseli
- StaÅ‚e elementy: zewnÄ™trzne Å›ciany + wewnÄ™trzne przeszkody
- **Start** (niebieskie kÃ³Å‚ko) â€“ pozycja poczÄ…tkowa agentÃ³w
- **Cel** (zielone kÃ³Å‚ko) â€“ punkt docelowy (promieÅ„ 12 px)

### 2. Agent â€“ inteligentny poruszajÄ…cy siÄ™ obiekt
- Reprezentowany przez kÃ³Å‚ko o promieniu 3 px
- WyposaÅ¼ony w **sieÄ‡ neuronowÄ…** i **system sensorÃ³w**
- MoÅ¼e otrzymywaÄ‡ ostrzeÅ¼enia kolizji (maks. 3), po ktÃ³rych ginie

### 3. SieÄ‡ neuronowa agenta
- **Warstwa wejÅ›ciowa:** 6 neuronÃ³w:
  - 4 sensory odlegÅ‚oÅ›ci od Å›cian (gÃ³ra, dÃ³Å‚, lewo, prawo)
  - 2 skÅ‚adowe znormalizowanego wektora do celu (kierunek)
- **Warstwa ukryta:** konfigurowalna (domyÅ›lnie 8 neuronÃ³w), funkcja aktywacji ReLU
- **Warstwa wyjÅ›ciowa:** 2 neurony â€“ prÄ™dkoÅ›Ä‡ w osi X i Y (zakres [-1,1] via tanh)
- **Inicjalizacja wag:** He (Kaiming) â€“ zapewnia stabilnoÅ›Ä‡ na starcie

### 4. Algorytm genetyczny
- **Populacja:** 100 agentÃ³w
- **Selekcja:** turniejowa (domyÅ›lnie 20 uczestnikÃ³w, opcja bez powtÃ³rzeÅ„)
- **KrzyÅ¼owanie:** jednopunktowe (losowy wybÃ³r wag od rodzicÃ³w)
- **Mutacja:** Gausowska z **normalizowanÄ… siÅ‚Ä…** â€“ siÅ‚a mutacji jest automatycznie skalowana przez Å›redniÄ… wartoÅ›Ä‡ bezwzglÄ™dnÄ… wag w danej warstwie
- **Elityzm:** najlepsze osobniki przechodzÄ… do nastÄ™pnej generacji (domyÅ›lnie 3)
- **Funkcja fitness:** opisana poniÅ¼ej

### 5. Funkcja przystosowania (fitness)
Fitness mierzy, jak dobrze agent radzi sobie z zadaniem. Maksymalna wartoÅ›Ä‡: **10.0**.

SkÅ‚adniki fitness:
- **Dotarcie do celu:** +10.0 + bonus za szybkoÅ›Ä‡
- **PostÄ™p w kierunku celu:** nagroda za zmniejszenie odlegÅ‚oÅ›ci (najlepsza i aktualna)
- **Bonus za przeÅ¼ycie:** +0.3 jeÅ›li agent Å¼yje
- **Bonus za eksploracjÄ™:** zachÄ™ta do ruchu w pÃ³Åºniejszych krokach
- **Bonus za unikanie kolizji:** zmniejsza siÄ™ z kaÅ¼dym ostrzeÅ¼eniem
- **Bonus za bliskoÅ›Ä‡ celu w koÅ„cowej fazie:** zachÄ™ta do â€dokoÅ„czeniaâ€ zadania

Funkcja jest **wypukÅ‚Ä… kombinacjÄ…** powyÅ¼szych skÅ‚adnikÃ³w, co zapewnia stabilnÄ… ewolucjÄ™.

#### 6. Kontrolki symulacji
- **Przycisk â€Restartâ€** â€“ rozpoczyna ewolucjÄ™ od nowa (zeruje wszystkie pokolenia)
- **Przycisk â€Pauza/WznÃ³wâ€** â€“ wstrzymuje/wznawia symulacjÄ™
- **Suwak prÄ™dkoÅ›ci** â€“ reguluje szybkoÅ›Ä‡ ruchu agentÃ³w (0.5x â€“ 2.0x)

#### 7. Parametry neuroewolucji
- **Neurony ukryte** (2â€“20) â€“ liczba neuronÃ³w w warstwie ukrytej sieci
- **WspÃ³Å‚czynnik mutacji** (1%â€“30%) â€“ prawdopodobieÅ„stwo mutacji pojedynczej wagi
- **Liczba elitarna** (1â€“10) â€“ ile najlepszych agentÃ³w przechodzi bez zmian do nastÄ™pnej generacji
- **Rozmiar turnieju** (5â€“50) â€“ liczba uczestnikÃ³w w kaÅ¼dym turnieju selekcji
- **Turniej bez powtÃ³rzeÅ„** â€“ checkbox zapobiegajÄ…cy wielokrotnemu udziaÅ‚owi tego samego agenta w turnieju

#### 8. Informacje o sieci neuronowej
- **Warstwa ukryta** â€“ aktualna liczba neuronÃ³w
- **WejÅ›cia/wyjÅ›cia** â€“ struktura sieci
- **Åšrednie wartoÅ›ci wag** W1 i W2 â€“ Å›rednia geometryczna wartoÅ›ci bezwzglÄ™dnych wag danej warstwy
- **Stosunek W2/W1** â€“ wskazuje, czy sieÄ‡ â€koncentruje siÄ™â€ bardziej na warstwie wyjÅ›ciowej (W2 > W1) czy ukrytej (W1 > W2)
- **Odchylenie std. fitness** â€“ miara zrÃ³Å¼nicowania przystosowania w populacji
- **OsiÄ…gnÄ™Å‚o cel** â€“ liczba agentÃ³w, ktÃ³re dotarÅ‚y do celu w bieÅ¼Ä…cej generacji

---

### 1. Wagi sieci neuronowej (W1, W2)
- **W1** â€“ macierz wag Å‚Ä…czÄ…cych warstwÄ™ wejÅ›ciowÄ… z ukrytÄ…. Rozmiar: `hidden Ã— 6`
- **W2** â€“ macierz wag Å‚Ä…czÄ…cych warstwÄ™ ukrytÄ… z wyjÅ›ciowÄ…. Rozmiar: `2 Ã— hidden`
- **Interpretacja wartoÅ›ci**: Wagi sÄ… inicjalizowane maÅ‚ymi liczbami losowymi z rozkÅ‚adu normalnego. W trakcie ewolucji wartoÅ›ci bezwzglÄ™dne wag rosnÄ…, gdy sieÄ‡ â€uczy siÄ™â€ silnych poÅ‚Ä…czeÅ„.

### 2. Stosunek wag W2/W1
- **W2/W1 â‰ˆ 1** â€“ obie warstwy majÄ… podobny wpÅ‚yw na wynik
- **W2/W1 > 1** â€“ warstwa wyjÅ›ciowa ma wiÄ™ksze znaczenie (czÄ™ste w pÃ³Åºnych fazach ewolucji)
- **W2/W1 < 1** â€“ warstwa ukryta dominuje (wczesna faza, sieÄ‡ uczy siÄ™ abstrakcyjnych reprezentacji)

### 3. Odchylenie standardowe fitness (Ïƒ)

Odchylenie standardowe fitness mierzy **zrÃ³Å¼nicowanie przystosowania** w populacji:

$$\sigma_f = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(f_i - \bar{f})^2}$$

gdzie $f_i$ to fitness i-tego agenta, a $\bar{f} = \frac{1}{N}\sum f_i$ to Å›redni fitness.

**Interpretacja wartoÅ›ci:**

| Zakres Ïƒ | Opis | Co to oznacza dla ewolucji |
|----------|------|---------------------------|
| **Ïƒ < 1** | Niskie | Populacja jednorodna â€“ wiÄ™kszoÅ›Ä‡ agentÃ³w ma podobny fitness. MoÅ¼e wskazywaÄ‡ na stagnacjÄ™ lub Å¼e wszyscy sÄ… jednakowo sÅ‚abi. |
| **1 < Ïƒ < 2.5** | Optymalne | Zdrowa rÃ³Å¼norodnoÅ›Ä‡ â€“ algorytm skutecznie selekcjonuje lepszych od gorszych. Ewolucja postÄ™puje. |
| **Ïƒ > 2.5** | Wysokie | DuÅ¼e zrÃ³Å¼nicowanie â€“ silna selekcja dziaÅ‚a. MoÅ¼e byÄ‡ okres przeÅ‚omowy (wielkie rÃ³Å¼nice miÄ™dzy najlepszymi a najgorszymi). |

**Uwaga:** WartoÅ›ci fitness sÄ… w zakresie 0â€“10, wiÄ™c Ïƒ = 2 oznacza, Å¼e typowy agent rÃ³Å¼ni siÄ™ od Å›redniej o okoÅ‚o 20% maksymalnego moÅ¼liwego fitness.

### 4. Liczba agentÃ³w, ktÃ³re osiÄ…gnÄ™Å‚y cel
- **0** â€“ Å¼aden agent jeszcze nie dotarÅ‚ (wczesna faza ewolucji)
- **1â€“10** â€“ pojedyncze sukcesy
- **>10** â€“ algorytm znalazÅ‚ dobre rozwiÄ…zanie, ktÃ³re jest kopiowane w populacji

### 5. SiÅ‚a mutacji i jej normalizacja
SiÅ‚a mutacji jest obliczana wedÅ‚ug wzoru:

$$\sigma_{mut} = \max(0.1, 0.3 \cdot multiplier \cdot e^{-g/500}) \cdot \frac{\bar{|w|}}{0.4}$$

gdzie:
- $g$ â€“ numer pokolenia
- $\bar{|w|}$ â€“ Å›rednia wartoÅ›Ä‡ bezwzglÄ™dna wag w danej warstwie
- $0.4$ â€“ referencyjna wartoÅ›Ä‡ poczÄ…tkowa (z inicjalizacji He)

**Kluczowa obserwacja:** ChoÄ‡ wykÅ‚adniczy czynnik $e^{-g/500}$ zmniejsza bazowÄ… siÅ‚Ä™ mutacji, to **normalizacja przez Å›redniÄ… wartoÅ›Ä‡ wag** kompensuje ten spadek. Gdy wagi rosnÄ… (co naturalnie dzieje siÄ™ podczas ewolucji), siÅ‚a mutacji rÃ³wnieÅ¼ roÅ›nie proporcjonalnie. DziÄ™ki temu mutacja jest **skalowana wzglÄ™dem aktualnej skali sieci** â€“ niezaleÅ¼nie od tego, czy wagi sÄ… maÅ‚e (start) czy duÅ¼e (po wielu pokoleniach), perturbacja jest zawsze proporcjonalna.

**Wynik:** SiÅ‚a mutacji utrzymuje siÄ™ na stabilnym poziomie poniÅ¼ej wartoÅ›ci maksymalnej, ale **roÅ›nie wraz z wagami**, zapewniajÄ…c ciÄ…gÅ‚Ä… eksploracjÄ™ nawet w pÃ³Åºnych fazach ewolucji.

---

### SygnaÅ‚y problemÃ³w
- **Stagnacja** â€“ fitness nie roÅ›nie przez >50 pokoleÅ„, Ïƒ bardzo niskie
  - *RozwiÄ…zanie*: zwiÄ™ksz wspÃ³Å‚czynnik mutacji, wÅ‚Ä…cz turniej bez powtÃ³rzeÅ„
- **Przedwczesna zbieÅ¼noÅ›Ä‡** â€“ populacja jednorodna, ale fitness niski
  - *RozwiÄ…zanie*: zmniejsz liczbÄ™ elit, zwiÄ™ksz rozmiar turnieju
- **Brak postÄ™pu** â€“ agenty ciÄ…gle ginÄ… na tej samej przeszkodzie
  - *RozwiÄ…zanie*: zwiÄ™ksz liczbÄ™ neuronÃ³w ukrytych, zmniejsz prÄ™dkoÅ›Ä‡

---

**Jak obliczane sÄ… Å›rednie wartoÅ›ci wag?**

Åšrednie wartoÅ›ci wag dla paskÃ³w gradientowych sÄ… obliczane jako **RMS (Root Mean Square)**:

$$\text{RMS}(W) = \sqrt{\frac{1}{N}\sum_{i,j} w_{ij}^2}$$

gdzie suma obejmuje wszystkie wagi w danej warstwie. UÅ¼ywamy RMS zamiast prostej Å›redniej arytmetycznej, poniewaÅ¼:
- UwzglÄ™dnia zarÃ³wno dodatnie, jak i ujemne wagi
- Jest miarÄ… "energii" lub "siÅ‚y" poÅ‚Ä…czeÅ„
- Jest naturalnÄ… miarÄ… w kontekÅ›cie inicjalizacji He/Kaiming




**Dlaczego warto Å›ledziÄ‡ te wskaÅºniki?**
- **RosnÄ…ce W1/W2** â€“ sieÄ‡ â€uczy siÄ™" silniejszych reprezentacji
- **W2/W1 bliskie 1** â€“ rÃ³wnowaga miÄ™dzy warstwami
- **W2/W1 > 1.5** â€“ warstwa wyjÅ›ciowa dominuje (czÄ™sto w fazie eksploatacji)
- **Wysokie Ïƒ** â€“ duÅ¼a rÃ³Å¼norodnoÅ›Ä‡, silna selekcja
- **Niskie Ïƒ** â€“ populacja jednorodna, ryzyko stagnacji

### Dostosowanie parametrÃ³w
- Wszystkie parametry moÅ¼na zmieniaÄ‡ **w trakcie dziaÅ‚ania** symulacji
- Zmiana liczby neuronÃ³w ukrytych lub prÄ™dkoÅ›ci powoduje **restart populacji**
- PozostaÅ‚e zmiany (mutacja, elity, turniej) obowiÄ…zujÄ… od **nastÄ™pnej generacji**

---

## SÅ‚ownik pojÄ™Ä‡

| Termin | Definicja  | Analogia biologiczna |
|--------|----------------------------|----------------------|
| **SieÄ‡ neuronowa** | Funkcja $f: \mathbb{R}^n \to \mathbb{R}^m$ zÅ‚oÅ¼ona z warstw liniowych przeplatanych nieliniowoÅ›ciami | MÃ³zg â€“ neurony poÅ‚Ä…czone synapsami |
| **Waga (weight)** | WspÃ³Å‚czynnik $w_{ij}$ w transformacji liniowej miÄ™dzy warstwami | SiÅ‚a poÅ‚Ä…czenia miÄ™dzy neuronami |
| **Fitness** | Skalarna funkcja celu $J(\theta)$ mierzÄ…ca jakoÅ›Ä‡ rozwiÄ…zania | Przystosowanie osobnika do Å›rodowiska |
| **Selekcja turniejowa** | WybÃ³r najlepszego z $k$ losowych osobnikÃ³w | Turniej â€“ zwyciÄ™zca przechodzi dalej |
| **KrzyÅ¼owanie (crossover)** | Losowa kombinacja genotypÃ³w dwÃ³ch rodzicÃ³w | Rekombinacja chromosomÃ³w |
| **Mutacja** | Dodanie szumu Gaussa do wagi z prawdopodobieÅ„stwem $p_m$ | Losowa zmiana w DNA |
| **Elityzm** | Zachowanie $e$ najlepszych rozwiÄ…zaÅ„ bez zmian | Ochrona gatunkÃ³w zagroÅ¼onych |
| **Odchylenie standardowe fitness** | $\sigma = \sqrt{\frac{1}{N}\sum_{i=1}^N (f_i - \bar{f})^2}$ | Miara zrÃ³Å¼nicowania w populacji |
| **Stosunek wag** | $r = \frac{\|W_2\|}{\|W_1\|}$ gdzie $\|W\|$ to norma Frobeniusa | Stosunek siÅ‚y poÅ‚Ä…czeÅ„ miÄ™dzy warstwami |

---


## ğŸ§¬ Model Algorytmu i Architektura

Ten projekt implementuje **NeuroewolucjÄ™ (Neuroevolution)** â€“ ewolucjÄ™ sieci neuronowych przy uÅ¼yciu algorytmu genetycznego, bez uÅ¼ycia propagacji wstecznej (gradient descent).

### 1. SieÄ‡ Neuronowa (Fenotyp)
Klasyczny **Perceptron Wielowarstwowy (MLP)** o staÅ‚ej topologii.
*   **WejÅ›cie (6):** OdlegÅ‚oÅ›ci od Å›cian (4 raycasty) + znormalizowany wektor do celu (2).
*   **Ukryta (8):** Warstwa z aktywacjÄ… **ReLU** (`max(0, x)`).
*   **WyjÅ›cie (2):** Wektor prÄ™dkoÅ›ci `(dx, dy)` z aktywacjÄ… **Tanh** (zakres `[-1, 1]`).
*   **Inicjalizacja:** He Initialization (`sqrt(2/n)`) â€“ kluczowe, by uniknÄ…Ä‡ zanikajÄ…cych gradientÃ³w (gdybyÅ›my uÅ¼ywali BP) i martwych neuronÃ³w.

### 2. Algorytm Genetyczny (Optymalizator)
To nie jest zwykÅ‚y GA. ZastosowÅ‚em kilka trikÃ³w:

| Operator | Metoda | Dlaczego taka? |
| :--- | :--- | :--- |
| **Selekcja** | **Turniejowa (Tournament)** | Szybka ($O(k)$), nie wymaga sortowania caÅ‚ej populacji. |
| **KrzyÅ¼owanie** | **Jednorodne (Uniform)** | KaÅ¼da waga losowo od rodzica A lub B. Lepsze niÅ¼ 1-point crossover dla macierzy wag. |
| **Mutacja** | **Adaptacyjna Gaussa** â­ | **NajwaÅ¼niejszy element.** SiÅ‚a mutacji skaluje siÄ™ do Å›redniej wartoÅ›ci wag w warstwie. Zapobiega "eksplozji" wag i pozwala na precyzyjny dostrÃ³j (fine-tuning). |
---

## ğŸ“Š OptymalnoÅ›Ä‡ i SkalowalnoÅ›Ä‡

### Czy ten model jest optymalny dla maÅ‚ej sieci?
**TAK.** To jest "sweet spot" neuroewolucji.
Dla ~74 wag (`(6+1)*8 + (8+1)*2`) prosty algorytm genetyczny zbiega siÄ™ szybciej niÅ¼ NEAT. NEAT traci czas na tworzenie nowych neuronÃ³w, ktÃ³rych tu nie potrzebujemy. Adaptacyjna mutacja dziaÅ‚a tu lepiej niÅ¼ staÅ‚y `mutation_rate`.
  - ÅÄ…czna pamiÄ™Ä‡ ~ `O(POP_SIZE Â· HIDDEN)`:
  - Przy `POP_SIZE=100, HIDDEN=8` â€“ Å›ladowe zuÅ¼ycie.
  - MoÅ¼na bez problemu dojÅ›Ä‡ rzÄ™du:
  - `HIDDEN ~ 100â€“200`,
  - `POP_SIZE ~ 10^3` (w JS w przeglÄ…darce to juÅ¼ gÃ³rna granica komfortu).

### Jak bardzo moÅ¼na to skalowaÄ‡?

| Parametr | Limit (w JS/Canvas) | Problem przy przekroczeniu |
| :--- | :--- | :--- |
| **Populacja** | **~300-500** | Spadek FPS. PÄ™tla `update()` jest synchroniczna. |
| **Neurony (Hidden)** | **~30-50** | PrzestrzeÅ„ poszukiwaÅ„ roÅ›nie kwadratowo ($O(N^2)$). PowyÅ¼ej 50 neuronÃ³w prosty GA zaczyna "bÅ‚Ä…dziÄ‡". |



### PorÃ³wnanie z innymi podejÅ›ciami (zÅ‚oÅ¼onoÅ›Ä‡ / dopasowanie)

**SieÄ‡:**
- W porÃ³wnaniu do:
  - gÅ‚Ä™bokich MLP, CNN, RNN/LSTM, NEAT/HyperNEAT â€“ ten model jest:
    - duÅ¼o **prostszÄ…** architekturÄ…,
    - w peÅ‚ni wystarczajÄ…cÄ… dla maÅ‚ego Å›rodowiska 2D z kilkoma sensorami,
    - lepiej skalowalny pamiÄ™ciowo przy maÅ‚ej liczbie neuronÃ³w (O(6Â·HIDDEN + HIDDENÂ·2) parametrÃ³w).

**Algorytm genetyczny:**
- W porÃ³wnaniu do:
  - bardziej zÅ‚oÅ¼onych metod ewolucyjnych (CMAâ€‘ES, NSGAâ€‘II, NEAT, ES z selfâ€‘adaptacjÄ…),
  - metod gradientowych (PPO, DQN, SAC),
- ten GA jest:
  - koncepcyjnie **bardzo prosty** (kilkadziesiÄ…t linii logiki),
  - dobrze dopasowany do maÅ‚ych sieci + maÅ‚ych populacji + prostych zadaÅ„ nawigacyjnych,
  - niewymagajÄ…cy obliczania gradientÃ³w ani konstrukcji funkcji wartoÅ›ci.

---

**Czas / skutecznoÅ›Ä‡:**

- KaÅ¼da generacja: `O(POP_SIZE Â· STEP_LIMIT Â· (koszt_sieci + koszt_Å›rodowiska))`.
- Dobrze siÄ™ skaluje do:
  - maÅ‚ych/w Å›rednich `HIDDEN` i `POP_SIZE` (rzÄ™du setek),
  - krÃ³tkich epizodÃ³w (`STEP_LIMIT` kilkaset).
- Przy bardzo duÅ¼ych sieciach lub dÅ‚ugich epizodach:
  - liczba osobnikÃ³w i generacji potrzebnych do dobrego rozwiÄ…zania roÅ›nie,
  - metoda staje siÄ™ **sÅ‚abo skalowalna** w porÃ³wnaniu z RL/gradientami.

---

### Podsumowanie

- **Rodzaj sieci:** maÅ‚y MLP `6 â†’ HIDDEN â†’ 2` z ReLU + tanh, uczony wyÅ‚Ä…cznie neuroewolucjÄ… (GA).
- **Algorytm genetyczny:** turniej + elita + proste krzyÅ¼owanie binarne + adaptowana siÅ‚a mutacji.
- **Charakterystyka:** bardzo prosty, intuicyjny, dobrze dopasowany do maÅ‚ych zadaÅ„ nawigacyjnych i maÅ‚ych sieci; nie jest optymalny dla duÅ¼ych problemÃ³w, ale do demonstracji neuroewolucji w labiryncie 2D sprawdza siÄ™ znakomicie.
